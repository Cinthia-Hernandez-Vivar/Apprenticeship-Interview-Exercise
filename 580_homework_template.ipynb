{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hrbyHqD_It1P"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cinthia-Hernandez-Vivar/Apprenticeship-Interview-Exercise/blob/main/580_homework_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qAAcaPbYaM6"
      },
      "source": [
        "# FINAL EXAM\n",
        "\n",
        "### **[CSCI 580](https://www.ecst.csuchico.edu/~bjuliano/csci580/)**, Spring 2024\n",
        "\n",
        "Cinthia Hernandez Vivar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYHU0ruKaRuA"
      },
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "I'm going to analyze the preformance of two machine learning models the GaussianNB and the DecisionTreeClassifier to predict survival outcomes for the passengers in the Titanic by comparing the attributes that lead to survival.\n",
        "\n",
        "Subtasks:\n",
        "\n",
        "1. Exploratory Data Analysis\n",
        "2. Model Selection\n",
        "3. Model Diagnostics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU48hEr2ai7_"
      },
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wdT3-m6_Wiy"
      },
      "source": [
        "## Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset = https://www.ecst.csuchico.edu/~bjuliano/csci580/ML/datasets/titanic.csv  \n",
        "\n",
        "I'm importing the libraries that are needed. Also loading the dataset and print some statistics."
      ],
      "metadata": {
        "id": "criLOKqIIQfR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxHj4pSwYRb8"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "titanic_df = pd.read_csv(\"https://www.ecst.csuchico.edu/~bjuliano/csci580/ML/datasets/titanic.csv\")\n",
        "\n",
        "# Display basic statistics of the dataset\n",
        "print(titanic_df.describe())\n",
        "\n",
        "# One-hot encode the 'sex' column\n",
        "titanic_df_encoded = pd.get_dummies(titanic_df, columns=['sex'])\n",
        "\n",
        "# Drop non-numeric columns and 'sex' column (as it's already encoded)\n",
        "numeric_columns = titanic_df_encoded.drop(['name', 'ticket', 'cabin', 'embarked', 'boat', 'home.dest', 'sex_male', 'sex_female'], axis=1)\n",
        "\n",
        "# Display correlation matrix\n",
        "print(numeric_columns.corr())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Q9Uii1_fRY"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe your process here ..."
      ],
      "metadata": {
        "id": "fQKnb2BoIRvl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ww_VB9N_ieI"
      },
      "source": [
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['pclass'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Pclass')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Pclass Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['sex'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Sex')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Sex Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['age'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Age Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['sibsp'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Sibsp')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(' Sibsp Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['parch'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Parch')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Parch Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Plot histograms for selected attributes\n",
        "plt.hist(titanic_df['fare'], bins=20, color='blue', alpha=0.7)\n",
        "plt.xlabel('Fare')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Fare Distribution')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection**"
      ],
      "metadata": {
        "id": "hrbyHqD_It1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe model here ..."
      ],
      "metadata": {
        "id": "hM9huVeuJAde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Selecting features and target variable\n",
        "X = titanic_df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
        "y = titanic_df['survived']\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Splitting dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "model_nbayes = GaussianNB()\n",
        "model_dtree = DecisionTreeClassifier()\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "model_nbayes.fit(X_train_imputed, y_train)\n",
        "model_dtree.fit(X_train_imputed, y_train)\n"
      ],
      "metadata": {
        "id": "I0D7HfbAJE08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4615de8a-8ec3-48c6-f85a-37186d1edb34"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Diagnostics**"
      ],
      "metadata": {
        "id": "y25wrG6RI17U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculations"
      ],
      "metadata": {
        "id": "26vb_aqBJHqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe your process here ..."
      ],
      "metadata": {
        "id": "a4owqazGJOJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Handle missing values in the original dataset\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize and train the Naive Bayes model\n",
        "model_nbayes = GaussianNB()\n",
        "model_nbayes.fit(X_train, y_train)\n",
        "# Evaluate Decision Tree model\n",
        "print(\"Decision Tree Model:\")\n",
        "print(\"Score:\", model_dtree.score(X_test, y_test))\n",
        "print(classification_report(y_test, model_dtree.predict(X_test)))"
      ],
      "metadata": {
        "id": "r2qA1ehKJYF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizations"
      ],
      "metadata": {
        "id": "iJ0ug7iZJUkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe your process here ..."
      ],
      "metadata": {
        "id": "4XW103qoJRE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_tree(model_dtree, filled=True, feature_names=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Il1aRfWBJZEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary and Conclusions**"
      ],
      "metadata": {
        "id": "akeKKwT2Jjft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this Exam I looked at the Titanic dataset and trained two models which are NaiveBayes and the DecisionTree and looked at their preformances to make a decision tree to see what attributes help the servival rate."
      ],
      "metadata": {
        "id": "XuT8v13IJoZp"
      }
    }
  ]
}